name: SaaS ETL Pipeline CI/CD

on:
  push:
    branches:
      - main # Aciona o workflow a cada push no branch 'main'

jobs:
  build-and-run:
    runs-on: ubuntu-latest # Usa a imagem mais recente do Ubuntu para rodar o job

    # REMOVA COMPLETAMENTE A SEÇÃO 'services: postgres:' JÁ QUE VAMOS USAR SQLITE
    # Se você tinha essa seção, apague-a por completo.
    # services:
    #   postgres:
    #     image: postgres:13
    #     env:
    #       POSTGRES_DB: ${{ secrets.DB_NAME }}
    #       POSTGRES_USER: ${{ secrets.DB_USER }}
    #       POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
    #     ports:
    #       - 5432:5432
    #     options: >-
    #       --health-cmd pg_isready
    #       --health-interval 10s
    #       --health-timeout 5s
    #       --health-retries 5

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10' # Use a versão exata do seu projeto

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Instale o PyMySQL mesmo que não vá usar agora, para manter consistência com requirements.txt
        pip install -r requirements.txt

    - name: Setup .env variables # Configure para SQLite
      run: |
        echo "DB_TYPE=sqlite" >> .env # AGORA É SQLITE!
        echo "SQLITE_DB_PATH=./data/saas_etl_data.db" >> .env # Caminho para o arquivo SQLite no ambiente do Actions
        # REMOVA QUALQUER LINHA DE DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD AQUI DENTRO,
        # pois não são mais necessárias para SQLite no Actions.
        # Essas variáveis agora serão ignoradas ou não precisarão existir para o SQLite.

    # REMOVA COMPLETAMENTE O PASSO 'Wait for PostgreSQL service'
    # - name: Wait for PostgreSQL service
    #   run: |
    #     # Loop para verificar a disponibilidade do banco de dados antes de continuar
    #     # ... (todo o código do pg_isready)

    - name: Run ETL Pipeline
      run: python -m src.main # Executa o pipeline usando a forma de módulo

    - name: Check for new data (Optional - example)
      run: |
        echo "Aguardando verificação de dados carregados no SQLite..."
        # Você pode adicionar um comando SQLite ou um script Python aqui para verificar o DB.
        # Ex: sqlite3 ./data/saas_etl_data.db "SELECT COUNT(*) FROM your_table_name;"
        # Certifique-se de que o sqlite3 esteja disponível no ambiente ou instale-o se for usar um comando direto.