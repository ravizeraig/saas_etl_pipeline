name: SaaS ETL Pipeline CI/CD

on:
  push:
    branches:
      - main # Aciona o workflow a cada push no branch 'main'

jobs:
  build-and-run:
    runs-on: ubuntu-latest # Usa a imagem mais recente do Ubuntu para rodar o job

    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_DB: ${{ secrets.DB_NAME }}
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout repository # Passo para clonar seu repositório
      uses: actions/checkout@v4

    - name: Set up Python # Passo para configurar o Python (versão 3.10, como você usa)
      uses: actions/setup-python@v5
      with:
        python-version: '3.10' # Use a versão exata do seu projeto

    - name: Install dependencies # Passo para instalar as dependências do seu requirements.txt
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Setup .env variables # Passo para configurar as variáveis de ambiente
      run: |
        echo "DB_TYPE=postgresql" >> .env # Se usar o serviço, o DB_TYPE é sempre postgresql
        echo "DB_HOST=postgres" >> .env  # <--- O HOST AGORA É 'postgres' (o nome do serviço)
        echo "DB_PORT=5432" >> .env       # A porta interna do container
        echo "DB_NAME=${{ secrets.DB_NAME }}" >> .env
        echo "DB_USER=${{ secrets.DB_USER }}" >> .env
        echo "DB_PASSWORD=${{ secrets.DB_PASSWORD }}" >> .env
        # Adicione outras variáveis se precisar, como SQLITE_DB_PATH
        # echo "SQLITE_DB_PATH=${{ secrets.SQLITE_DB_PATH }}" >> .env

    - name: Wait for PostgreSQL service # NOVO PASSO: Espera o DB ficar pronto
      run: |
        # Loop para verificar a disponibilidade do banco de dados antes de continuar
        # Isso usa 'pg_isready' que é um comando de cliente do PostgreSQL
        # e tenta por 30 segundos (30 * 1 segundo de sleep)
        for i in $(seq 1 30); do
          /usr/bin/pg_isready -h postgres -p 5432 -U ${{ secrets.DB_USER }} && break
          echo "Waiting for PostgreSQL service... ($i/30)"
          sleep 1
        done
        # Se após o loop ainda não estiver pronto, sai com erro
        /usr/bin/pg_isready -h postgres -p 5432 -U ${{ secrets.DB_USER }} || exit 1
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }} # pg_isready precisa da senha como env var

    - name: Run ETL Pipeline # Passo para executar o seu script principal do pipeline
      run: python -m src.main # Executa o pipeline usando a forma de módulo

    - name: Check for new data (Optional - example) # Exemplo: um passo para verificar se a carga funcionou
      run: |
        # Este é um placeholder. Você pode adicionar um script Python ou comando SQL
        # para verificar se novos dados foram carregados ou se a tabela existe.
        echo "Aguardando verificação de dados carregados..."